{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "y[y==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n"
     ]
    }
   ],
   "source": [
    "# 划分数据\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造弱分类器的决策函数g(X)\n",
    "def _G(fi,fv,direct):\n",
    "    assert direct in [\"positive\",\"nagetive\"]\n",
    "    def _g(X):\n",
    "        if direct  == \"positive\":\n",
    "            predict = (X[:,fi] <= fv) * -1 # which <= value assign -1 else 0\n",
    "        else:\n",
    "            predict = (X[:,fi] > fv) * -1 # which > value assign 0 else -1\n",
    "        predict[predict == 0] = 1\n",
    "        return predict \n",
    "    return _g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1\n",
      " -1]\n",
      "[ 1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1\n",
      " -1]\n"
     ]
    }
   ],
   "source": [
    "#验证是否有效\n",
    "func = _G(0,5,\"positive\")\n",
    "print(func(X_test))\n",
    "result = np.zeros_like(X_test[:,0],dtype=np.int32)\n",
    "result[X_test[:,0]<=5] = -1\n",
    "result[X_test[:,0]>5] = 1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.8 5.1 5.7 5.4 5.7 7.  5.7 4.5 5.  5.3 6.9 5.2 4.9 4.7 4.9 4.8 6.4 5.\n",
      " 5.1 5.1 4.4 5.  5.2 5.7 4.6]\n",
      "[20  7 24 13 15 14 12  8 21 17 18 19  1 22 11  9  3  2 23  4  6  0 16 10\n",
      "  5]\n"
     ]
    }
   ],
   "source": [
    "arr = X_test[:,0]\n",
    "index = np.argsort(arr)\n",
    "predict = np.zeros_like(arr,dtype=np.int32)\n",
    "# direct = postive\n",
    "predict[arr <= 5] = -1\n",
    "predict[arr > 5] = 1\n",
    "# direct = nagetive\n",
    "predict[arr <= 5] = 1\n",
    "predict[arr > 5] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择最佳的划分点,即求出fi和fv\n",
    "def best_split(X,y,w):\n",
    "    best_err = 1e10\n",
    "    best_fi = None\n",
    "    best_fv = None\n",
    "    best_direct = None\n",
    "    for fi in range(X.shape[1]):\n",
    "        series = X[:,fi]\n",
    "        for fv in np.sort(series):\n",
    "            predict = np.zeros_like(arr,dtype=np.int32)\n",
    "            # direct = postive\n",
    "            predict[arr <= fv] = -1\n",
    "            predict[arr > fv] = 1\n",
    "            err = np.sum((predict != y)* 1 * w)\n",
    "            print(\"err = {} ,fi={},fv={},direct={}\".format(err,fi,fv,\"postive\"))\n",
    "            if err < best_err:\n",
    "                best_err = err\n",
    "                best_fi = fi\n",
    "                best_fv = fv\n",
    "                best_direct = \"positive\"\n",
    "            \n",
    "            # direct = nagetive\n",
    "            predict = predict * -1\n",
    "            err = np.sum((predict != y) * 1 * w)\n",
    "            if err < best_err:\n",
    "                best_err = err\n",
    "                best_fi = fi\n",
    "                best_fv = fv\n",
    "                best_direct = \"nagetive\"\n",
    "            print(\"err = {} ,fi={},fv={},direct={}\".format(err,fi,fv,\"nagetive\"))\n",
    "    return best_err,best_fi,best_fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err = 0.39999999999999997 ,fi=0,fv=4.4,direct=postive\n",
      "err = 0.6000000000000001 ,fi=0,fv=4.4,direct=nagetive\n",
      "err = 0.4 ,fi=0,fv=4.6,direct=postive\n",
      "err = 0.6000000000000001 ,fi=0,fv=4.6,direct=nagetive\n",
      "err = 0.36 ,fi=0,fv=4.7,direct=postive\n",
      "err = 0.6400000000000001 ,fi=0,fv=4.7,direct=nagetive\n",
      "err = 0.36 ,fi=0,fv=4.7,direct=postive\n",
      "err = 0.6400000000000001 ,fi=0,fv=4.7,direct=nagetive\n",
      "err = 0.4 ,fi=0,fv=4.8,direct=postive\n",
      "err = 0.6000000000000001 ,fi=0,fv=4.8,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=5.1,direct=postive\n",
      "err = 0.52 ,fi=0,fv=5.1,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=5.1,direct=postive\n",
      "err = 0.52 ,fi=0,fv=5.1,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=5.1,direct=postive\n",
      "err = 0.52 ,fi=0,fv=5.1,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.4,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.4,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.5,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.5,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.5,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.5,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.5,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.5,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.6,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.6,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.7,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.7,direct=nagetive\n",
      "err = 0.56 ,fi=0,fv=5.7,direct=postive\n",
      "err = 0.44 ,fi=0,fv=5.7,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=5.8,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=5.8,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=5.8,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=5.8,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=5.8,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=5.8,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=6.0,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=6.0,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=6.2,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=6.2,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=6.7,direct=postive\n",
      "err = 0.52 ,fi=0,fv=6.7,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=6.7,direct=postive\n",
      "err = 0.52 ,fi=0,fv=6.7,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=6.7,direct=postive\n",
      "err = 0.52 ,fi=0,fv=6.7,direct=nagetive\n",
      "err = 0.48 ,fi=0,fv=6.8,direct=postive\n",
      "err = 0.52 ,fi=0,fv=6.8,direct=nagetive\n",
      "err = 0.52 ,fi=0,fv=6.9,direct=postive\n",
      "err = 0.48000000000000004 ,fi=0,fv=6.9,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.2,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.2,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.3,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.3,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.4,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.4,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.5,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.5,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.6,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.6,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.7,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.7,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.7,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.7,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.8,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.8,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=2.8,direct=postive\n",
      "err = 0.56 ,fi=1,fv=2.8,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.0,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.0,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.0,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.0,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.1,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.1,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.1,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.1,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.1,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.1,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.1,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.1,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.2,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.2,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.2,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.4,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.4,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.4,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.4,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=3.5,direct=postive\n",
      "err = 0.56 ,fi=1,fv=3.5,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=4.0,direct=postive\n",
      "err = 0.56 ,fi=1,fv=4.0,direct=nagetive\n",
      "err = 0.44 ,fi=1,fv=4.2,direct=postive\n",
      "err = 0.56 ,fi=1,fv=4.2,direct=nagetive\n",
      "err = 0.39999999999999997 ,fi=1,fv=4.4,direct=postive\n",
      "err = 0.6000000000000001 ,fi=1,fv=4.4,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.2,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.2,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.3,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.3,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.3,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.3,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.4,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.4,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.4,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.4,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.4,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.4,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.5,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.5,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.5,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.5,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.6,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.6,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.6,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.6,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=1.7,direct=postive\n",
      "err = 0.56 ,fi=2,fv=1.7,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=3.0,direct=postive\n",
      "err = 0.56 ,fi=2,fv=3.0,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=3.8,direct=postive\n",
      "err = 0.56 ,fi=2,fv=3.8,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=3.9,direct=postive\n",
      "err = 0.56 ,fi=2,fv=3.9,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.0,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.0,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.0,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.0,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.0,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.0,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.1,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.1,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.2,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.2,direct=nagetive\n",
      "err = 0.39999999999999997 ,fi=2,fv=4.4,direct=postive\n",
      "err = 0.6000000000000001 ,fi=2,fv=4.4,direct=nagetive\n",
      "err = 0.44 ,fi=2,fv=4.5,direct=postive\n",
      "err = 0.56 ,fi=2,fv=4.5,direct=nagetive\n",
      "err = 0.36 ,fi=2,fv=4.7,direct=postive\n",
      "err = 0.6400000000000001 ,fi=2,fv=4.7,direct=nagetive\n",
      "err = 0.4 ,fi=2,fv=4.8,direct=postive\n",
      "err = 0.6000000000000001 ,fi=2,fv=4.8,direct=nagetive\n",
      "err = 0.48000000000000004 ,fi=2,fv=4.9,direct=postive\n",
      "err = 0.52 ,fi=2,fv=4.9,direct=nagetive\n",
      "err = 0.52 ,fi=2,fv=5.0,direct=postive\n",
      "err = 0.48 ,fi=2,fv=5.0,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=0.4,direct=postive\n",
      "err = 0.56 ,fi=3,fv=0.4,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.0,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.0,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.1,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.1,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.1,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.1,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.2,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.2,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.3,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.3,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.3,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.3,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.3,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.3,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.4,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.4,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.4,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.4,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.5,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.5,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.5,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.5,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.5,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.5,direct=nagetive\n",
      "err = 0.44 ,fi=3,fv=1.7,direct=postive\n",
      "err = 0.56 ,fi=3,fv=1.7,direct=nagetive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36, 0, 4.7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.ones_like(y_test) / len(y_test)\n",
    "best_split(X_test,y_test,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Adaboost类\n",
    "class MyAdaboost:\n",
    "    def __init__(self,n_estimators):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.clfs = []\n",
    "        self.alphas = []\n",
    "        self.weights = None\n",
    "        \n",
    "    # 构造弱分类器的决策函数g(X)\n",
    "    def _G(self,fi,fv,direct):\n",
    "        assert direct in [\"positive\",\"nagetive\"]\n",
    "        def _g(X):\n",
    "            if direct  == \"positive\":\n",
    "                predict = (X[:,fi] <= fv) * -1 # which <= value assign -1 else 0\n",
    "            else:\n",
    "                predict = (X[:,fi] > fv) * -1 # which > value assign 0 else -1\n",
    "            predict[predict == 0] = 1\n",
    "            return predict \n",
    "        return _g\n",
    "    \n",
    "    #选择最佳的划分点,即求出fi和fv\n",
    "    def _best_split(self,X,y,w):\n",
    "        best_err = 1e10\n",
    "        best_fi = None\n",
    "        best_fv = None\n",
    "        best_direct = None\n",
    "        for fi in range(X.shape[1]):\n",
    "            series = X[:,fi]\n",
    "            for fv in np.sort(series):\n",
    "                predict = np.zeros_like(series,dtype=np.int32)\n",
    "                # direct = postive\n",
    "                predict[series <= fv] = -1\n",
    "                predict[series > fv] = 1\n",
    "                err = np.sum((predict != y)* 1 * w)\n",
    "#                 print(\"err = {} ,fi={},fv={},direct={}\".format(err,fi,fv,\"postive\"))\n",
    "                if err < best_err:\n",
    "                    best_err = err\n",
    "                    best_fi = fi\n",
    "                    best_fv = fv\n",
    "                    best_direct = \"positive\"\n",
    "\n",
    "                # direct = nagetive\n",
    "                predict = predict * -1\n",
    "                err = np.sum((predict != y) * 1 * w)\n",
    "                if err < best_err:\n",
    "                    best_err = err\n",
    "                    best_fi = fi\n",
    "                    best_fv = fv\n",
    "                    best_direct = \"nagetive\"\n",
    "#                 print(\"err = {} ,fi={},fv={},direct={}\".format(err,fi,fv,\"nagetive\"))\n",
    "        return best_err,best_fi,best_fv,best_direct\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.weights = np.ones_like(y_train) / len(y_train)\n",
    "        for i in tqdm(range(self.n_estimators)):\n",
    "            err,fi,fv,direct = self._best_split(X_train,y_train,self.weights)\n",
    "#             print(i,err,fi,fv,direct)\n",
    "            \n",
    "            #计算G(x)的系数alpha\n",
    "            alpha = 0.5 * np.log((1-err)/err)\n",
    "#             print(\"alpha:\",alpha)\n",
    "            self.alphas.append(alpha)\n",
    "            \n",
    "            #求出G\n",
    "            g = self._G(fi,fv,direct)\n",
    "            self.clfs.append(g)\n",
    "            \n",
    "            #更新weights\n",
    "            self.weights = self.weights * np.exp(-1 * alpha * y_train * g(X_train))\n",
    "            self.weights = self.weights / np.sum(self.weights)\n",
    "#             print(\"weights :\",self.weights)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        y_p = np.array([self.alphas[i] * self.clfs[i](X_test) for i in range(self.n_estimators)])\n",
    "        y_p = np.sum(y_p,axis=0)\n",
    "        y_predict = np.zeros_like(y_p,dtype=np.int32)\n",
    "        y_predict[y_p>=0] = 1\n",
    "        y_predict[y_p<0] = -1\n",
    "        return y_predict\n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        y_predict = self.predict(X_test)\n",
    "        return np.sum(y_predict == y_test)/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██            | 15/100 [00:10<01:02,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "clf = MyAdaboost(100)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2066797492479762,\n",
       " 0.9550334856259718,\n",
       " 0.7280236332199983,\n",
       " 0.574744258124658,\n",
       " 0.5305756803245693,\n",
       " 0.5488124453500542,\n",
       " 0.5164893968884653,\n",
       " 0.7115468708060274,\n",
       " 0.5488704763454592,\n",
       " 0.46235040922771986,\n",
       " 0.4883250757386486,\n",
       " 0.5061749527598064,\n",
       " 0.4240888782159666,\n",
       " 0.37139973176105384,\n",
       " 0.43847670325361054,\n",
       " 0.3689905768000123,\n",
       " 0.5068965593580707,\n",
       " 0.43674441980251866,\n",
       " 0.4399053806155735,\n",
       " 0.43306302771093685,\n",
       " 0.44886654167747586,\n",
       " 0.4007204086507429,\n",
       " 0.4722227450410171,\n",
       " 0.35923642958961316,\n",
       " 0.3633716916478892,\n",
       " 0.40126177773996724,\n",
       " 0.37663499088442176,\n",
       " 0.36401475830098734,\n",
       " 0.38712120079271817,\n",
       " 0.39093350186253584,\n",
       " 0.4186782807358294,\n",
       " 0.447724528818573,\n",
       " 0.4312228161738305,\n",
       " 0.3465552872834859,\n",
       " 0.39104986965625116,\n",
       " 0.3416801285781792,\n",
       " 0.4031125271095423,\n",
       " 0.37382776743813634,\n",
       " 0.4874404750589538,\n",
       " 0.3606102636298511,\n",
       " 0.3875307104547722,\n",
       " 0.3313073088126768,\n",
       " 0.4193157028932447,\n",
       " 0.4113822401339551,\n",
       " 0.38751171515359295,\n",
       " 0.3778569230619695,\n",
       " 0.39922644445777233,\n",
       " 0.40162082201807103,\n",
       " 0.3348381879684409,\n",
       " 0.4128920390819238,\n",
       " 0.3117000225815162,\n",
       " 0.39751627022448155,\n",
       " 0.3433755041119996,\n",
       " 0.376549310420276,\n",
       " 0.4240320456805494,\n",
       " 0.3335485399533991,\n",
       " 0.29906913752316483,\n",
       " 0.2780290305973897,\n",
       " 0.40463615833850053,\n",
       " 0.36323517382240716,\n",
       " 0.3285089013962278,\n",
       " 0.3489290503499332,\n",
       " 0.361749175672195,\n",
       " 0.42104732091623404,\n",
       " 0.31091972095766773,\n",
       " 0.32039950855804467,\n",
       " 0.3666921603652857,\n",
       " 0.33062353110853104,\n",
       " 0.3673013726775229,\n",
       " 0.4689553194038771,\n",
       " 0.3503049720839276,\n",
       " 0.340828326715348,\n",
       " 0.3960136731054723,\n",
       " 0.3908325230455896,\n",
       " 0.37066753510418005,\n",
       " 0.32948040875526946,\n",
       " 0.31996725403795606,\n",
       " 0.35305983311825917,\n",
       " 0.4111583393172639,\n",
       " 0.39156009542472475,\n",
       " 0.33227426963327295,\n",
       " 0.35860210435963147,\n",
       " 0.3740415963042078,\n",
       " 0.3092925922638982,\n",
       " 0.37139792805323774,\n",
       " 0.3787846890634508,\n",
       " 0.33093954293948247,\n",
       " 0.37748831158038226,\n",
       " 0.3597050442317518,\n",
       " 0.31330511148903434,\n",
       " 0.31497458797559874,\n",
       " 0.3540254643612712,\n",
       " 0.3426984893859774,\n",
       " 0.3726722685705554,\n",
       " 0.35885497262376537,\n",
       " 0.39090309040610755,\n",
       " 0.3790762458781575,\n",
       " 0.33305000619280506,\n",
       " 0.3008651393998721,\n",
       " 0.37372480123702284]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.        , 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.        , 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.        , 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.        , 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.        , 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301, 0.00699301, 0.00699301,\n",
       "       0.00699301, 0.00699301, 0.00699301])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
